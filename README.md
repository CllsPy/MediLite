# medlite
O objetivo do projeto era experimentar com [LFM2-1.2B-GGUF](https://huggingface.co/LiquidAI/LFM2-1.2B-GGUF). Por se apresentar um modelo leve sendo capaz inclusive de rodar via CPU. Pelo seu tamanho, tarefas como condificação apresentam grande limitações. 

## Porque?
Partimos do pressuposto de que uma qualidade maior de parâmetros implica modelos melhores, nessa direção o uso dos modelos generativos se restrige a quem possui grande poder de harware, a alternativa os Small Language models se provaram democráticos e eficientes em certas tarefas quando treinados com dataset específicos [Ronen Eldan & Yuanzhi Li, 2023](https://arxiv.org/abs/2305.07759)
